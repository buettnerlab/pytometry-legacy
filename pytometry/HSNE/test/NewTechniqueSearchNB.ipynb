{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felix/anaconda3/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version.  The public classes are available in the top-level namespace.\n",
      "  from pandas.core.index import RangeIndex\n"
     ]
    }
   ],
   "source": [
    "# add parent directory to path for importing HSNE modules\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import scanpy as sc\n",
    "import anndata\n",
    "import plotting as pl\n",
    "import tools as tl\n",
    "import numpy as np\n",
    "import time as time\n",
    "\n",
    "# Load Dataset\n",
    "filelocation = r\"datasets/VBh_converted.h5ad\"\n",
    "adata = anndata.read_h5ad(filelocation)\n",
    "\n",
    "# subsampling\n",
    "sc.pp.subsample(adata, 0.1)\n",
    "\n",
    "# normalizing\n",
    "adata.X = np.arcsinh(adata.X / 10)\n",
    "\n",
    "# calc knn\n",
    "sc.pp.neighbors(adata, n_neighbors=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calc_P(T):\n",
    "    return (T + T.transpose()) / (2 * T.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, spdiags\n",
    "from scipy.sparse.linalg import eigs\n",
    "\n",
    "def fresh_calc_T(adata):\n",
    "    \n",
    "\n",
    "    # get connectivities from adata\n",
    "    c = adata.obsp['connectivities']\n",
    "\n",
    "    # make sure connectivities are symmetric\n",
    "    assert(len((c - c.T).data) == 0), \"connectivities are not symmetric\"\n",
    "\n",
    "    # row-normalise c to give a transition matrix\n",
    "    T = c.multiply(csr_matrix(1.0 / np.abs(c).sum(1)))\n",
    "\n",
    "    # make sure it's correctly row-normalised\n",
    "    assert(np.allclose(T.sum(1), 1)), \"T is not row-normalised\"\n",
    "\n",
    "    # compute the stationary distribution\n",
    "    #from scipy.sparse.linalg import eigs\n",
    "    D, V = eigs(T.T, which='LM')\n",
    "    pi = V[:, 0]\n",
    "\n",
    "    # make sure pi is entirely real\n",
    "    assert((pi.imag == 0).all()), \"This is not the stationary vector, found imaginary entries\"\n",
    "    pi = pi.real\n",
    "\n",
    "    # make sure all entries have the same sign\n",
    "    assert((pi > 0).all() or (pi < 0).all()), \"This is not the stationary vector, found positive and negative entries\"\n",
    "    pi /= pi.sum()\n",
    "\n",
    "    # check pi is normalised correctly\n",
    "    assert(np.allclose(pi.sum(), 1)), \"Pi is not normalized correctly\"\n",
    "\n",
    "    # put the stationary dist into a diag matrix\n",
    "    Pi = spdiags(pi, 0, pi.shape[0], pi.shape[0])\n",
    "\n",
    "    # finally, check for reversibility of T\n",
    "    assert(np.allclose((Pi @ T - T.T @ Pi).data, 0))\n",
    "    \n",
    "    return T\n",
    "    \n",
    "t0_new = time.time()\n",
    "T_new = fresh_calc_T(adata)\n",
    "t1_new = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compared to old method for calculating T\n",
    "import multiprocessing as mp\n",
    "from scipy.special import softmax\n",
    "from scipy.stats import entropy\n",
    "\n",
    "def _calc_first_T(distances_nn, dim):\n",
    "    p = mp.Pool(mp.cpu_count())\n",
    "    probs = p.map(_helper_method_calc_T, [dist.data for dist in distances_nn])\n",
    "    p.terminate()\n",
    "    p.join()\n",
    "    data = []\n",
    "    for pr in probs:\n",
    "        data.extend(pr)\n",
    "    T = csr_matrix((data, distances_nn.indices, distances_nn.indptr), shape=(dim,dim))\n",
    "    return T\n",
    "\n",
    "def _helper_method_calc_T(dist):\n",
    "    d = dist / np.max(dist)\n",
    "    return softmax((-d ** 2) / _binary_search_sigma(d, len(d)))\n",
    "\n",
    "def _binary_search_sigma(d, n_neigh):\n",
    "    # binary search\n",
    "    sigma = 10  # Start Sigma\n",
    "    goal = np.log(n_neigh)  # log(k) with k being n_neighbors\n",
    "    # Do binary search until entropy ~== log(k)\n",
    "    while True:\n",
    "        ent = entropy(softmax((-d ** 2) / sigma))\n",
    "        # check sigma\n",
    "        if np.isclose(ent, goal):\n",
    "            return sigma\n",
    "        if ent > goal:\n",
    "            sigma *= 0.5\n",
    "        else:\n",
    "            sigma /= 0.5\n",
    "\n",
    "\n",
    "t0_old = time.time()\n",
    "T_old = _calc_first_T(adata.obsp['distances'], len(adata.X))\n",
    "\n",
    "t1_old = time.time()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--NEW--\n",
      "shape: (12946, 12946)\n",
      "length: 348030\n",
      "sum of data: 12945.99999087235\n",
      "sum first row P 7.912657000918663e-05\n",
      "sum first row T 1.0000000521540642\n",
      "time: 1.366792917251587\n",
      "\n",
      "--OLD--\n",
      "shape: (12946, 12946)\n",
      "length: 245974\n",
      "sum of data: 12945.99999999991\n",
      "sum first row P 8.126529182022665e-05\n",
      "sum first row T 0.9999999999999999\n",
      "time: 8.002951622009277\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"--NEW--\")\n",
    "print(f\"shape: {np.shape(T_new)}\")\n",
    "print(f\"length: {len(T_new.data)}\")\n",
    "print(f\"sum of data: {sum(T_new.data)}\")\n",
    "P_new = _calc_P(T_new)\n",
    "print(f\"sum first row P {sum(sum((P_new.getrow(0)).toarray()))}\")\n",
    "print(f\"sum first row T {sum(sum((T_new.getrow(0)).toarray()))}\")\n",
    "print(f\"time: {t1_new-t0_new}\\n\")\n",
    "\n",
    "print(\"--OLD--\")\n",
    "print(f\"shape: {np.shape(T_old)}\")\n",
    "print(f\"length: {len(T_old.data)}\")\n",
    "print(f\"sum of data: {sum(T_old.data)}\")\n",
    "P_old = _calc_P(T_old)\n",
    "print(f\"sum first row P {sum(sum((P_old.getrow(0)).toarray()))}\")\n",
    "print(f\"sum first row T {sum(sum((T_old.getrow(0)).toarray()))}\")\n",
    "print(f\"time: {t1_old-t0_old}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old\n",
      "1.0000000521540642\n",
      "0.23137873\n",
      "\n",
      "New\n",
      "0.9999999999999999\n",
      "0.05415735182233375\n"
     ]
    }
   ],
   "source": [
    "print(\"Old\")\n",
    "print(sum(T_new.toarray()[0]))\n",
    "print(max(T_new.data))\n",
    "\n",
    "\n",
    "print(\"\\nNew\")\n",
    "print(sum(T_old.toarray()[0]))\n",
    "print(max(T_old.data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
